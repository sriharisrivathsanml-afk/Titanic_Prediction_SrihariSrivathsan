{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1MENZaN0_TcKesqEvAyVw1IJe8-2yKrAD",
      "authorship_tag": "ABX9TyMitrkqmIMJvnFhoGMg4mVf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sriharisrivathsanml-afk/Titanic_Prediction_SrihariSrivathsan/blob/main/MY_FIRST_MODEL\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# INTRODUCTION\n",
        "\n",
        "This is the notebook that trains on the titanic dataset. I am using my current understanding of Machine Learning to predict whether a person On board the Titanic dataset has survived or not."
      ],
      "metadata": {
        "id": "Whjom7A2tVWk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# STEPS OF EXECUTION OF THE PROJECT\n",
        "\n",
        "1. Load and Understand the Data\n",
        "2. Prepare the data (cleaning , adding features , etc. )\n",
        "3. Train on models\n",
        "4. Evaluate models\n",
        "5. Deploy"
      ],
      "metadata": {
        "id": "Y9sOrRf8uBoD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNDERSTANDING THE DATASETS\n",
        "There are two datasets that are present in this project :\n",
        "\n",
        "\n",
        "\n",
        "*   train.csv (contains 12 columns)\n",
        "*   test.csv  (contains 11 columns - the Survived column is absent)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# DESCRIPTION OF EACH COLUMN\n",
        "\n",
        "\n",
        "*   PassengerID - ID of the passenger travelling\n",
        "*   Survived - Whether the particular person survived or not ( 0 or 1 )\n",
        "*   PClass - The class of ticket purchased ( 1 , 2 , 3)\n",
        "*   Name - Name of the passenger\n",
        "*   Sex - Male or Female\n",
        "*   Age\n",
        "*   SibSp - no of siblings/spouses\n",
        "*   Parch - Number of parents / children\n",
        "*   Ticket - Ticket Number\n",
        "*   Fare - Passenger fare in pounds\n",
        "*   Cabin - Cabin Numbers\n",
        "*   Embarked - The port in which the passenger boarded the Titanic Ship\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KDmWYp7lumiP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Neccessary Modules"
      ],
      "metadata": {
        "id": "QjgJkNOXQoVC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing the basic modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request as retrieve\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "metadata": {
        "id": "hbIOMYhCzDoD"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading the data\n",
        "\n",
        "\n",
        "raw_train_set , raw_test_set = pd.read_csv(\"/content/train.csv\" , on_bad_lines = \"skip\"),pd.read_csv(\"/content/test.csv\" , on_bad_lines = \"skip\")\n"
      ],
      "metadata": {
        "id": "FULvQQ6b3fWe"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing"
      ],
      "metadata": {
        "id": "qlaTU8_bQiTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Columns to be taken under consideration\n",
        "\n",
        "Features :-\n",
        "\n",
        "\n",
        "*   Pclass\n",
        "*   Sex\n",
        "*   Age\n",
        "*   SibSp\n",
        "*   Parch\n",
        "*   Fare\n",
        "*   Embarked\n",
        "\n",
        "Target:-\n",
        "\n",
        "\n",
        "*   Survived\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qiPor1xghNN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Preparing the data\n",
        "train_set = raw_train_set.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "SN52RF1L9-ap"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting statistical data from the training set\n",
        "print(\"NULL VALUES CHECK:-\")\n",
        "print(train_set.isnull().sum())\n",
        "\n",
        "print(\"Mean age :- \",train_set[\"Age\"].mean())\n",
        "print(\"Median age :- \",train_set[\"Age\"].median())\n",
        "print(\"Standard deviation of age :- \",train_set[\"Age\"].std())\n",
        "\n",
        "print(\"Mean SibSp :- \",train_set[\"SibSp\"].mean())\n",
        "print(\"Median SibSp :- \",train_set[\"SibSp\"].median())\n",
        "print(\"Standard deviation of SibSp :- \",train_set[\"SibSp\"].std())\n",
        "\n",
        "print(\"Mean parch :- \",train_set[\"Parch\"].mean())\n",
        "print(\"Median parch :- \",train_set[\"Parch\"].median())\n",
        "print(\"Standard deviation of parch :- \",train_set[\"Parch\"].std())\n",
        "\n",
        "print(\"Mean fare :- \",train_set[\"Fare\"].mean())\n",
        "print(\"Median fare :- \",train_set[\"Fare\"].median())\n",
        "print(\"Standard deviation of fare :- \",train_set[\"Fare\"].std())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjdV4aeDPUAh",
        "outputId": "38effec3-a209-4cb6-d91d-2e3ea4e6ca34"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NULL VALUES CHECK:-\n",
            "Survived      0\n",
            "Pclass        0\n",
            "Sex           0\n",
            "Age         177\n",
            "SibSp         0\n",
            "Parch         0\n",
            "Fare          0\n",
            "Embarked      2\n",
            "dtype: int64\n",
            "Mean age :-  29.69911764705882\n",
            "Median age :-  28.0\n",
            "Standard deviation of age :-  14.526497332334044\n",
            "Mean SibSp :-  0.5230078563411896\n",
            "Median SibSp :-  0.0\n",
            "Standard deviation of SibSp :-  1.1027434322934275\n",
            "Mean parch :-  0.38159371492704824\n",
            "Median parch :-  0.0\n",
            "Standard deviation of parch :-  0.8060572211299559\n",
            "Mean fare :-  32.204207968574636\n",
            "Median fare :-  14.4542\n",
            "Standard deviation of fare :-  49.693428597180905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Filling empty age records with median values\n",
        "\n",
        "imputer = SimpleImputer(strategy=\"median\")\n",
        "train_set_age = train_set[[\"Age\"]]\n",
        "\n",
        "train_set[\"Age\"] = imputer.fit_transform(train_set_age)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_L-frtv9lJHm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converting Sex category into binary attributes\n",
        "\n",
        "train_set[\"Sex\"] = train_set[\"Sex\"].map({\"male\": 0, \"female\": 1})\n"
      ],
      "metadata": {
        "id": "mftfJ6mCp95p"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorizing the fare column\n",
        "\n",
        "train_set_fare = train_set[\"Fare\"].sort_values()\n",
        "cut_points= train_set_fare.quantile([0.33,0.67,1])\n",
        "print(cut_points)\n",
        "train_set[\"Fare_Categories\"] = pd.to_numeric(pd.cut(train_set[\"Fare\"],bins=[0.,8.61295,26.25000,512.32920],labels=[1,2,3]))"
      ],
      "metadata": {
        "id": "ZA1TCJXWqUCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9fcc4f-13ff-4f8a-fb22-1ab8b78f1688"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.33      8.61295\n",
            "0.67     26.25000\n",
            "1.00    512.32920\n",
            "Name: Fare, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling the Embarked Column and applying one-hot encoding\n",
        "\n",
        "embarked_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "train_set[\"Embarked\"]=embarked_imputer.fit_transform(train_set[[\"Embarked\"]])[:,0]\n",
        "\n",
        "embarked_dummies_train = pd.get_dummies(train_set[\"Embarked\"], prefix='Embarked')\n",
        "train_set = pd.concat([train_set, embarked_dummies_train], axis=1)\n",
        "\n",
        "\n",
        "train_set[\"Embarked_C\"]=train_set[\"Embarked_C\"].map({False:0,True:1})\n",
        "train_set[\"Embarked_Q\"]=train_set[\"Embarked_Q\"].map({False:0,True:1})\n",
        "train_set[\"Embarked_S\"]=train_set[\"Embarked_S\"].map({False:0,True:1})\n",
        "\n"
      ],
      "metadata": {
        "id": "nKMDhqibyAuV"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Handling null values in Fare_Categories column\n",
        "\n",
        "fare_categories_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "train_set[\"Fare_Categories\"]=embarked_imputer.fit_transform(train_set[[\"Fare_Categories\"]])[:,0]"
      ],
      "metadata": {
        "id": "FfwJYEp-0y0t"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the output csv\n",
        "train_set.to_csv(\"output_train_1.csv\")"
      ],
      "metadata": {
        "id": "ScCylYDF9WOR"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fetching the output.csv file to delete the Embarked Column and storing the survived Column\n",
        "\n",
        "train_set = pd.read_csv(\"/content/output_train_1.csv\").drop([\"Embarked\",\"Unnamed: 0\"],axis=1)\n",
        "target_train_set = train_set[\"Survived\"]\n",
        "train_set = train_set.drop(\"Survived\",axis=1)"
      ],
      "metadata": {
        "id": "0dJD78hFcFGI"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Setting up target variables\n",
        "\n",
        "target_train_set_0=(target_train_set==0)\n",
        "\n",
        "target_train_set_1=(target_train_set==1)"
      ],
      "metadata": {
        "id": "9aMBR1S9mSho"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling non - categorical numeric values\n",
        "\n",
        "std_scaler_age=StandardScaler()\n",
        "std_scaler_fare=StandardScaler()\n",
        "train_set[\"Age\"]=std_scaler_age.fit_transform(train_set[[\"Age\"]])\n",
        "train_set[\"Fare\"]=std_scaler_fare.fit_transform(train_set[[\"Fare\"]])"
      ],
      "metadata": {
        "id": "-1A3m5s1Hzwp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the training data\n",
        "\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "splits = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=42)\n",
        "\n",
        "for train_idx , test_idx in splits.split(train_set,train_set[\"Fare_Categories\"]):\n",
        "  strat_train_train_set = train_set.loc[train_idx]\n",
        "  strat_train_test_set = train_set.loc[test_idx]\n",
        "\n",
        "  strat_target_train_train_set_0 = target_train_set_0.loc[train_idx]\n",
        "  strat_target_train_test_set_0 = target_train_set_0.loc[test_idx]\n",
        "  strat_target_train_train_set_1 = target_train_set_1.loc[train_idx]\n",
        "  strat_target_train_test_set_1 = target_train_set_1.loc[test_idx]"
      ],
      "metadata": {
        "id": "GtkBY2rznzU0"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Adding Total_Family_Members and isAlone columns to increase number of feautres and better train the model\n",
        "strat_train_train_set[\"Family_Size\"]=strat_train_train_set[\"SibSp\"]+strat_train_train_set[\"Parch\"]+1\n",
        "strat_train_train_set[\"isAlone\"]=(strat_train_train_set[\"Family_Size\"]==1).astype(int)\n",
        "\n",
        "strat_train_test_set[\"Family_Size\"]=strat_train_test_set[\"SibSp\"]+strat_train_test_set[\"Parch\"]+1\n",
        "strat_train_test_set[\"isAlone\"]=(strat_train_test_set[\"Family_Size\"]==1).astype(int)\n",
        "\n"
      ],
      "metadata": {
        "id": "YPaMsttXixqQ"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting data of Family_Size Column\n",
        "print(\"Mean family size :- \",0.5*(strat_train_train_set[\"Family_Size\"].mean()+strat_train_test_set[\"Family_Size\"].mean()))\n",
        "print(\"Median family size :- \",0.5*(strat_train_train_set[\"Family_Size\"].median()+strat_train_test_set[\"Family_Size\"].median()))\n",
        "print(\"Standard deviation of family size :- \",0.5*(strat_train_train_set[\"Family_Size\"].std()+strat_train_test_set[\"Family_Size\"].std()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqiR3xgofLbX",
        "outputId": "f08bfc23-0978-4075-8941-c14b0bf255cd"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean family size :-  1.852484935032327\n",
            "Median family size :-  1.0\n",
            "Standard deviation of family size :-  1.5667894108084777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Scaling the Family_Size column normally\n",
        "std_scaler_members=StandardScaler()\n",
        "strat_train_train_set[\"Family_Size\"] = std_scaler_members.fit_transform(strat_train_train_set[[\"Family_Size\"]])\n",
        "strat_train_test_set[\"Family_Size\"] = std_scaler_members.fit_transform(strat_train_test_set[[\"Family_Size\"]])\n",
        "strat_train_train_set[\"SibSp\"] = std_scaler_members.fit_transform(strat_train_train_set[[\"SibSp\"]])\n",
        "strat_train_test_set[\"SibSp\"] = std_scaler_members.fit_transform(strat_train_test_set[[\"SibSp\"]])\n",
        "strat_train_train_set[\"Parch\"] = std_scaler_members.fit_transform(strat_train_train_set[[\"Parch\"]])\n",
        "strat_train_test_set[\"Parch\"] = std_scaler_members.fit_transform(strat_train_test_set[[\"Parch\"]])\n"
      ],
      "metadata": {
        "id": "MDc0fR82qY0s"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dropping the fare_categories column\n",
        "strat_train_train_set=strat_train_train_set.drop(\"Fare_Categories\",axis=1)\n",
        "strat_train_test_set=strat_train_test_set.drop(\"Fare_Categories\",axis=1)\n",
        "print(strat_train_train_set.head())\n",
        "print(strat_train_test_set.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTbOwbBph99u",
        "outputId": "d7af0a5f-3adc-42dd-8e0a-c11830356ed0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Pclass  Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
            "204       3    0 -0.873136 -0.482509 -0.486053 -0.486337           0   \n",
            "150       2    0  1.662909 -0.482509 -0.486053 -0.396235           0   \n",
            "602       1    0 -0.104637 -0.482509 -0.486053  0.205289           0   \n",
            "10        3    1 -1.949034  0.396126  0.758802 -0.312172           0   \n",
            "201       3    0 -0.104637  6.546575  2.003656  0.751946           0   \n",
            "\n",
            "     Embarked_Q  Embarked_S  Family_Size  isAlone  \n",
            "204           0           1    -0.572720        1  \n",
            "150           0           1    -0.572720        1  \n",
            "602           0           1    -0.572720        1  \n",
            "10            0           1     0.646344        0  \n",
            "201           0           1     5.522600        0  \n",
            "     Pclass  Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
            "152       3    0  2.008733 -0.446571 -0.425657 -0.486337           0   \n",
            "478       3    0 -0.565736 -0.446571 -0.425657 -0.496993           0   \n",
            "295       1    0 -0.104637 -0.446571 -0.425657 -0.090272           1   \n",
            "53        2    1 -0.027788  0.619245 -0.425657 -0.124920           0   \n",
            "385       2    0 -0.873136 -0.446571 -0.425657  0.831478           0   \n",
            "\n",
            "     Embarked_Q  Embarked_S  Family_Size  isAlone  \n",
            "152           0           1    -0.514478        1  \n",
            "478           0           1    -0.514478        1  \n",
            "295           0           0    -0.514478        1  \n",
            "53            0           1     0.157723        0  \n",
            "385           0           1    -0.514478        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training models\n",
        "\n",
        "Models to be evaluated :\n",
        "\n",
        "1.   SGDCClassifier\n",
        "2.   RandomForestClassifier\n",
        "3.   LogisticRegression\n",
        "4.   KNNeighborsClassifier\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DnZY8SWInAAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluating the logistic regression model\n",
        "log_regression = LogisticRegression(C=0.35938137,max_iter=10000,random_state=42)\n",
        "log_regression_accuracies=cross_val_score(log_regression,strat_train_train_set,strat_target_train_train_set_0,cv=5,scoring=\"accuracy\")\n",
        "print(log_regression_accuracies.mean())"
      ],
      "metadata": {
        "id": "pTQS05dLsqf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55187fab-7af7-4409-8365-30fab05b1160"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8145474244065791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating a SGDCClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "sgd_classifier = SGDClassifier(random_state=42)\n",
        "\n",
        "\n",
        "sgd_classifier_accuracies=cross_val_score(sgd_classifier,strat_train_train_set,strat_target_train_train_set_0,cv=5,scoring=\"accuracy\")\n",
        "print(sgd_classifier_accuracies.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edhh-NgXpPIJ",
        "outputId": "dbe89729-c9a4-4b50-b8af-8e7f91ee1b34"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7808037033389146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating a RandomForestClassifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_classifier = RandomForestClassifier(random_state=42)\n",
        "accuracies_rf_classifier=cross_val_score(rfc_classifier,strat_train_train_set,strat_target_train_train_set_0,cv=5,scoring=\"accuracy\")\n",
        "print(accuracies_rf_classifier.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwal8HuhrPUE",
        "outputId": "f849d8af-630f-4120-97f2-238c7f2dd94f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.792150103417709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating a KNegihbors classifier\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "kn_classifier = KNeighborsClassifier(n_neighbors=19,weights='uniform')\n",
        "accuracies_kn_classifier=cross_val_score(kn_classifier,strat_train_train_set,strat_target_train_train_set_0,cv=5,scoring=\"accuracy\")\n",
        "print(accuracies_kn_classifier.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSpbrMREteKj",
        "outputId": "aac4808e-fb3e-4996-dcfa-13525ab097f8"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7963360583078893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tuning hyperparameters for the Kneighbors classifier using GridSearch\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    'n_neighbors': [i for i in range(1,100)],\n",
        "    'weights': ['uniform', 'distance']\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(kn_classifier, param_grid, cv=5)\n",
        "grid_search.fit(strat_train_train_set,strat_target_train_train_set_0)\n",
        "\n",
        "print(grid_search.best_params_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dINJ1nxu0Qs",
        "outputId": "178873ce-b1e4-4228-bc45-53bcbbb25265"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'n_neighbors': 17, 'weights': 'uniform'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Selecting and Tuning the model\n",
        "\n",
        "Model selected :- Logistic Regression"
      ],
      "metadata": {
        "id": "742S6gylhsA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting the best C parameter for Logistic Regression\n",
        "\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "log_reg_cv = LogisticRegressionCV(cv=5, max_iter=1000)\n",
        "log_reg_cv.fit(strat_train_train_set,strat_target_train_train_set_0)\n",
        "\n",
        "print(\"Best C:\", log_reg_cv.C_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAvddzv3upP",
        "outputId": "9a78242c-73fc-4fa7-e7f8-93374e30c128"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best C: [0.35938137]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "scores = cross_val_score(LogisticRegression(C=0.35938137,max_iter=10000,random_state=42), strat_train_train_set,strat_target_train_train_set_0, cv=cv,scoring=\"accuracy\",n_jobs=-1)\n",
        "\n",
        "print(\"Mean accuracies :\",scores.mean())\n",
        "print(\"All accuracies:\", scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G037BiroprIr",
        "outputId": "f68883b1-26a9-4607-f5e9-2cbe091e1782"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracies : 0.8202304737516005\n",
            "All accuracies: [0.81818182 0.81818182 0.81690141 0.83802817 0.80985915]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final dataset\n",
        "\n",
        "#Storing the final strat_train_train_set and strat_train_test_set locally\n",
        "strat_train_train_set.to_csv(\"strat_train_train_set.csv\",index=False)\n",
        "strat_train_test_set.to_csv(\"strat_train_test_set.csv\",index=False)\n",
        "strat_target_train_train_set_0.to_csv(\"strat_target_train_train_set.csv\",index=False)\n",
        "strat_target_train_test_set_0.to_csv(\"strat_target_train_test_set.csv\",index=False)"
      ],
      "metadata": {
        "id": "SQar2fUBlBw1"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaning the test set"
      ],
      "metadata": {
        "id": "tAb69gDeP2JG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #Cleaning the test set\n",
        "\n",
        "\n",
        "'''Mean age :-  29.36158249158249\n",
        "Median age :-  28.0\n",
        "Standard deviation of age :-  13.019696550973194\n",
        "Mean SibSp :-  0.5230078563411896\n",
        "Median SibSp :-  0.0\n",
        "Standard deviation of SibSp :-  1.1027434322934275\n",
        "Mean parch :-  0.38159371492704824\n",
        "Median parch :-  0.0\n",
        "Standard deviation of parch :-  0.8060572211299559\n",
        "Mean fare :-  32.204207968574636\n",
        "Median fare :-  14.4542\n",
        "Standard deviation of fare :-  49.693428597180905\n",
        "Mean family size :-  1.1010937034133123e-17\n",
        "Median family size :-  -0.5435992339894096\n",
        "Standard deviation of family size :-  1.0017540211914666'''\n",
        "\n",
        "#Dropping Unwanted columns\n",
        "passenger_ids = raw_test_set[\"PassengerId\"]\n",
        "test_set = raw_test_set.drop([\"PassengerId\",\"Name\",\"Ticket\",\"Cabin\"],axis=1)\n",
        "\n",
        "\n",
        "\n",
        "#Checking the null values in each column\n",
        "print(test_set.isnull().sum())\n",
        "\n",
        "#Categorizing Sex Column\n",
        "test_set[\"Sex\"]=test_set[\"Sex\"].map({\"male\":0,\"female\":1})\n",
        "\n",
        "#Imputing numeric columns\n",
        "def impute_numeric(X,train_median_value):\n",
        "  X=X.fillna(train_median_value)\n",
        "  return X\n",
        "\n",
        "def scale_numeric(X,train_mean_value,train_std_value):\n",
        "  return (X-train_mean_value)/(train_std_value)\n",
        "\n",
        "\n",
        "test_set[\"Age\"]=impute_numeric(test_set[\"Age\"],28.0)\n",
        "test_set[\"Fare\"]=impute_numeric(test_set[\"Fare\"],14.4542)\n",
        "test_set[\"Age\"]=scale_numeric(test_set[\"Age\"],29.36158249158249,13.019696550973194)\n",
        "test_set[\"Fare\"]=scale_numeric(test_set[\"Fare\"],32.204207968574636,49.693428597180905)\n",
        "\n",
        "test_set[\"Family_Size\"]=test_set[\"SibSp\"]+test_set[\"Parch\"]+1\n",
        "test_set[\"isAlone\"]=(test_set[\"Family_Size\"]==1).astype(int)\n",
        "\n",
        "test_set[\"SibSp\"]=scale_numeric(test_set[\"SibSp\"],0.5230078563411896,1.1027434322934275)\n",
        "test_set[\"Parch\"]=scale_numeric(test_set[\"Parch\"],0.38159371492704824,0.8060572211299559)\n",
        "test_set[\"Family_Size\"]=scale_numeric(test_set[\"Family_Size\"],1.1010937034133123e-17,1.0017540211914666)\n",
        "\n",
        "#Handling the Embarked Column and applying one-hot encoding\n",
        "embarked_dummies_test = pd.get_dummies(test_set[\"Embarked\"], prefix='Embarked')\n",
        "test_set = pd.concat([test_set, embarked_dummies_test], axis=1)\n",
        "\n",
        "test_set[\"Embarked_C\"]=test_set[\"Embarked_C\"].map({False:0,True:1})\n",
        "test_set[\"Embarked_Q\"]=test_set[\"Embarked_Q\"].map({False:0,True:1})\n",
        "test_set[\"Embarked_S\"]=test_set[\"Embarked_S\"].map({False:0,True:1})\n",
        "\n",
        "def reorder_columns(df, reference_columns):\n",
        "    # Drop any extra columns not in reference\n",
        "    df = df[reference_columns]\n",
        "\n",
        "    return df\n",
        "#Reorder the columns\n",
        "train_feature_order=[\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Embarked_C\",\"Embarked_Q\",\"Embarked_S\",\"Family_Size\",\"isAlone\"]\n",
        "test_set = reorder_columns(test_set, train_feature_order)\n",
        "\n",
        "#Final output csv\n",
        "test_set.to_csv(\"output_test_set.csv\",index = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac6Vh7kGSfW2",
        "outputId": "1e9e9566-1f2e-499c-dc92-41939dc16ca9"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pclass       0\n",
            "Sex          0\n",
            "Age         86\n",
            "SibSp        0\n",
            "Parch        0\n",
            "Fare         1\n",
            "Embarked     0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running the Model on the test set And Creating a CSV File of the Tests"
      ],
      "metadata": {
        "id": "clbEWEEXP_WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Running the logistic regression model\n",
        "\n",
        "log_regression = LogisticRegression(C=0.35938137,max_iter=10000,random_state=42)\n",
        "log_regression.fit(strat_train_train_set,strat_target_train_train_set_0)\n",
        "predictions = log_regression.predict(test_set).astype(int)\n",
        "print(predictions)\n",
        "print(len(predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8nIbhM-h7Dn",
        "outputId": "e59ea5f8-4296-4e6a-d150-2442820087a4"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1\n",
            " 0 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 0 1 1 1 1 1 0 1 1 1 0 1 0 0 1 1 1 0 1 1 1\n",
            " 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 1 0 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1\n",
            " 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 0 0 1 1 0 1 0\n",
            " 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 0 1 0 1\n",
            " 0 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 0 1 0 1 1 1 1 1 0\n",
            " 1 1 1 0 0 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 0 1 1 1 1\n",
            " 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 1 0 1 1 1 0 1 1\n",
            " 0 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1\n",
            " 1 0 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 1 0 1 1 1 1\n",
            " 1 0 0 0 0 1 1 0 1 1 1]\n",
            "418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating a kaggle style submission.csv file\n",
        "submission_df=pd.DataFrame({\"PassengerId\":passenger_ids,\"Survived\":predictions})\n",
        "submission_df[\"Survived\"] = 1 - submission_df[\"Survived\"]\n",
        "submission_df.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "thKTYA2qyZGX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis after round 1 of Training and Testing (accuracy = 0.77272)"
      ],
      "metadata": {
        "id": "-F70LNCfAttq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature importances --> each and every feature's contribution to the chance of survival\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": strat_train_train_set.columns,\n",
        "    \"Coefficient\": log_regression.coef_[0]\n",
        "}).sort_values(by=\"Coefficient\", ascending=False)\n",
        "\n",
        "print(feature_importance)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyVWHVXIA3zi",
        "outputId": "1cf577c3-13d0-41a0-94dc-2ece0efb094d"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        Feature  Coefficient\n",
            "0        Pclass     0.866293\n",
            "10      isAlone     0.749471\n",
            "2           Age     0.382841\n",
            "3         SibSp     0.303047\n",
            "8    Embarked_S     0.273103\n",
            "9   Family_Size     0.271076\n",
            "4         Parch     0.124262\n",
            "7    Embarked_Q    -0.110334\n",
            "5          Fare    -0.140740\n",
            "6    Embarked_C    -0.163370\n",
            "1           Sex    -2.531099\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Recreating the training dataset with target values\n",
        "strat_train_train_set[\"Survived\"]=strat_target_train_train_set_0\n",
        "strat_train_train_set.to_csv(\"train_with_survived_target.csv\",index=False)"
      ],
      "metadata": {
        "id": "bUskJGlG_GkV"
      },
      "execution_count": 66,
      "outputs": []
    }
  ]
}